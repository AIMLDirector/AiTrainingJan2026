{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "785f10bb-4964-470a-afc5-edcab5d3cbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /Users/premkumargontrand/AITraining/AIvenv/lib/python3.11/site-packages (4.4.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Users/premkumargontrand/AITraining/AIvenv/lib/python3.11/site-packages (from gensim) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /Users/premkumargontrand/AITraining/AIvenv/lib/python3.11/site-packages (from gensim) (1.16.1)\n",
      "Requirement already satisfied: smart_open>=1.8.1 in /Users/premkumargontrand/AITraining/AIvenv/lib/python3.11/site-packages (from gensim) (7.3.0.post1)\n",
      "Requirement already satisfied: wrapt in /Users/premkumargontrand/AITraining/AIvenv/lib/python3.11/site-packages (from smart_open>=1.8.1->gensim) (1.17.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef3e2abd-f020-45cd-9910-b7e7eda6a5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec, fasttext, basemodel\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re,string  # filter the special character \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5345dd3e-25ea-4682-9d9c-267d7a48edee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"Artificial intelligence is transforming the world we live in.\",\n",
    "    \"Deep learning techniques have greatly improved image recognition.\",\n",
    "    \"Natural language processing allows computers to understand human language.\",\n",
    "    \"Data science combines statistics, computer science, and domain knowledge.\",\n",
    "    \"The weather is nice today, perfect for a walk in the park.\",\n",
    "    \"Cats are often seen as independent and curious creatures.\",\n",
    "    \"The stock market fluctuates based on various economic indicators.\",\n",
    "    \"Exploring new cuisines can be an exciting culinary adventure.\",\n",
    "    \"Machine learning algorithms can learn from data and make predictions.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c467c2f-91f5-494d-8177-6583cfc0484f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the quick brown fox jumps over the lazy dog.\n",
      "the quick brown fox jumps over the lazy dog\n",
      "artificial intelligence is transforming the world we live in.\n",
      "artificial intelligence is transforming the world we live in\n",
      "deep learning techniques have greatly improved image recognition.\n",
      "deep learning techniques have greatly improved image recognition\n",
      "natural language processing allows computers to understand human language.\n",
      "natural language processing allows computers to understand human language\n",
      "data science combines statistics, computer science, and domain knowledge.\n",
      "data science combines statistics computer science and domain knowledge\n",
      "the weather is nice today, perfect for a walk in the park.\n",
      "the weather is nice today perfect for a walk in the park\n",
      "cats are often seen as independent and curious creatures.\n",
      "cats are often seen as independent and curious creatures\n",
      "the stock market fluctuates based on various economic indicators.\n",
      "the stock market fluctuates based on various economic indicators\n",
      "exploring new cuisines can be an exciting culinary adventure.\n",
      "exploring new cuisines can be an exciting culinary adventure\n",
      "machine learning algorithms can learn from data and make predictions.\n",
      "machine learning algorithms can learn from data and make predictions\n",
      "[['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog'], ['artificial', 'intelligence', 'is', 'transforming', 'the', 'world', 'we', 'live', 'in'], ['deep', 'learning', 'techniques', 'have', 'greatly', 'improved', 'image', 'recognition'], ['natural', 'language', 'processing', 'allows', 'computers', 'to', 'understand', 'human', 'language'], ['data', 'science', 'combines', 'statistics', 'computer', 'science', 'and', 'domain', 'knowledge'], ['the', 'weather', 'is', 'nice', 'today', 'perfect', 'for', 'a', 'walk', 'in', 'the', 'park'], ['cats', 'are', 'often', 'seen', 'as', 'independent', 'and', 'curious', 'creatures'], ['the', 'stock', 'market', 'fluctuates', 'based', 'on', 'various', 'economic', 'indicators'], ['exploring', 'new', 'cuisines', 'can', 'be', 'an', 'exciting', 'culinary', 'adventure'], ['machine', 'learning', 'algorithms', 'can', 'learn', 'from', 'data', 'and', 'make', 'predictions']]\n"
     ]
    }
   ],
   "source": [
    "cleaned_sentences = []\n",
    "for sentence in sentences:\n",
    "    sentence = sentence.lower()\n",
    "    print(sentence)\n",
    "    sentence = re.sub(r'[' + string.punctuation + ']', '', sentence)  # Remove punctuation ( $%#@!&^*().,::\") \n",
    "    print(sentence)\n",
    "    words = sentence.split()\n",
    "    cleaned_sentences.append(words)\n",
    "\n",
    "print(cleaned_sentences) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6ea36e4-4e98-4f35-a039-5b0a7e8d9c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Word2Vec model\n",
    "model = Word2Vec(sentences=cleaned_sentences, vector_size=100, window=5, min_count=1, workers=4, sg=1)\n",
    "\n",
    "# Train the model\n",
    "model.train(sentences, total_words=len(sentences), epochs=10)  # Adjust epochs according to your needs\n",
    "\n",
    "# Save the model\n",
    "model.save('word2vec_model.model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76c2215f-15a6-422a-a98e-0fd9fea50e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=79, vector_size=100, alpha=0.025>\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c5f1e11-447e-4559-96df-8590dcc72c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0051498  -0.00667948 -0.0077697   0.00831258 -0.00198273 -0.00689253\n",
      " -0.00414924  0.00517428 -0.00288122 -0.00376904  0.00163665 -0.00278708\n",
      " -0.00160085  0.00111066 -0.00296765  0.0085183   0.00392017 -0.00995823\n",
      "  0.00625676 -0.00676851  0.00078421  0.00440893 -0.00508102 -0.00212465\n",
      "  0.00810152 -0.0042472  -0.00763639  0.00927969 -0.00215663 -0.00471138\n",
      "  0.00859302  0.00429346  0.00434058  0.00926152 -0.00845499  0.00525674\n",
      "  0.00204402  0.00418135  0.00168743  0.00445703  0.00450176  0.0060974\n",
      " -0.00320345 -0.00457746 -0.00042345  0.00254356 -0.00326871  0.00605075\n",
      "  0.00416312  0.00777326  0.00257781  0.00810041 -0.00139046  0.00807567\n",
      "  0.0037219  -0.00804201 -0.00392529 -0.00246542  0.00489675 -0.00086644\n",
      " -0.00284059  0.0078309   0.00931595 -0.00162088 -0.00516567 -0.00467811\n",
      " -0.00485365 -0.00959655  0.00134951 -0.00420634  0.00251737  0.00562211\n",
      " -0.00404262 -0.00959014  0.00156948 -0.00671456  0.00250273 -0.00378503\n",
      "  0.00706262  0.00063138  0.00354338 -0.00272883 -0.00174386  0.00766546\n",
      "  0.0014027  -0.00585793 -0.00782198  0.00122729  0.00645939  0.00556688\n",
      " -0.0089531   0.0085823   0.00404989  0.00746665  0.0097495  -0.0072768\n",
      " -0.00902039  0.00583369  0.00938638  0.00350375]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv['predictions'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10e84508-6d1f-4252-a5b0-3264424e0712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are: 0.34957218170166016\n",
      "fluctuates: 0.30550336837768555\n",
      "knowledge: 0.24735164642333984\n",
      "lazy: 0.22147904336452484\n",
      "on: 0.17857569456100464\n"
     ]
    }
   ],
   "source": [
    "# Get word vectors\n",
    "#print(model.wv['cats'])  # Example: Vector for 'cat'\n",
    "\n",
    "# Find similar words\n",
    "similar_words = model.wv.most_similar('learning', topn=5)\n",
    "#print(similar_words)\n",
    "for word, similarity in similar_words:\n",
    "    print(f\"{word}: {similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1943562c-670f-4031-8299-45db8fd3d6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "from gensim.utils import simple_preprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f529aa6e-4598-4bb4-907a-4d9550bbdc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = FastText(\n",
    "    sentences=cleaned_sentences,\n",
    "    vector_size=100,  # Desired dimensionality of word vectors\n",
    "    window=5,         # Context window size\n",
    "    min_count=1,      # Ignore words with frequency lower than this\n",
    "    epochs=10,        # Number of training epochs\n",
    "    min_n=3,          # Minimum length of character n-grams\n",
    "    max_n=6           # Maximum length of character n-grams\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17c4e67b-54fa-4e8f-8dbc-68a6679f512e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"Training complete!\")\n",
    "\n",
    "# You can save the trained model for later use\n",
    "model_ft.save(\"fasttext.model\")\n",
    "\n",
    "# Load a saved model\n",
    "# model_ft = FastText.load(\"fasttext.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a947788-a90e-4a24-b0d3-3a088d4a64eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText<vocab=79, vector_size=100, alpha=0.025>\n"
     ]
    }
   ],
   "source": [
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79914d34-08fd-4195-8585-88c187655e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.81109863e-04 -3.23919184e-03 -2.98799510e-04 -2.95782840e-04\n",
      "  7.74465501e-04  8.73204553e-04 -3.47495428e-03  2.57962180e-04\n",
      "  1.79446186e-03  1.24865235e-03  3.66322725e-04 -7.53869361e-04\n",
      "  1.47234381e-03  1.97704672e-03 -5.78669307e-04  5.78373496e-04\n",
      " -2.57748854e-03  1.97880995e-03  6.82824699e-04  1.23018635e-05\n",
      "  9.02743486e-04  8.31018260e-04 -5.97956823e-04  1.02865940e-03\n",
      "  8.34737031e-04 -2.51948228e-03 -1.00764446e-04 -2.61294679e-03\n",
      "  1.12038676e-03  2.83887074e-03  2.68450659e-03  1.47404347e-03\n",
      "  6.48048765e-04  2.25037173e-03  2.89233169e-03 -4.28716978e-03\n",
      " -2.15795255e-04 -1.08418718e-03 -1.33549713e-03 -9.48978239e-04\n",
      " -1.44730409e-04 -1.03815075e-03  1.42869671e-04  3.40425060e-04\n",
      " -2.35586846e-03 -1.93966829e-04  2.17532972e-03  2.30622943e-04\n",
      "  7.46831123e-04 -2.08780076e-03  7.89732614e-04 -4.32343734e-03\n",
      "  1.15050538e-03  1.69190764e-03 -2.01083696e-03  2.54766177e-03\n",
      "  1.81555888e-03  1.48110092e-03  1.52853213e-03  9.94900547e-05\n",
      "  2.87181116e-04 -4.09184489e-04 -9.69240093e-04  1.36531028e-03\n",
      "  2.00103386e-03  2.57234758e-04  1.71187264e-03 -1.19107077e-03\n",
      "  6.70754293e-04  2.65415222e-03 -2.77921441e-04 -6.90707646e-04\n",
      "  1.42376719e-03 -2.36685923e-03 -1.39429653e-03 -8.87621893e-04\n",
      "  7.33227993e-04  6.53243391e-04  2.41756369e-03 -1.58799390e-04\n",
      " -9.77149699e-04 -9.92171350e-04  7.58425740e-04 -4.07567527e-03\n",
      " -1.28883880e-03  1.46610022e-04  2.47568023e-05 -6.98338787e-04\n",
      " -1.14910083e-03 -2.05825642e-03 -9.77127696e-04 -1.39949995e-03\n",
      "  1.30740937e-03  1.75405398e-03 -1.56248559e-03  1.28327729e-03\n",
      "  1.82011630e-04 -1.05963845e-03  6.46761269e-04 -2.65264680e-04]\n",
      "computers: 0.7463644742965698\n",
      "learning: 0.29301178455352783\n",
      "are: 0.22786082327365875\n",
      "combines: 0.17049665749073029\n",
      "language: 0.1669132560491562\n"
     ]
    }
   ],
   "source": [
    "# Get word vectors\n",
    "print(model_ft.wv['cats'])  # Example: Vector for 'cat'\n",
    "\n",
    "# Find similar words\n",
    "similar_words = model_ft.wv.most_similar('computer', topn=5)\n",
    "#print(similar_words)\n",
    "for word, similarity in similar_words:\n",
    "    print(f\"{word}: {similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "917fa3dd-ced5-4ed3-9467-3e029b5bfec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.6899683e-04  1.5090426e-03 -8.8849763e-04 -1.2423326e-03\n",
      "  5.1380059e-04 -1.7634614e-03  5.9120165e-04 -2.5552004e-03\n",
      "  2.8505819e-03  1.2320583e-03  5.3197274e-04 -1.7677039e-04\n",
      " -2.0836717e-04 -3.2284842e-03 -1.2341731e-04  1.9441907e-03\n",
      " -1.3435563e-03  1.4128465e-03 -1.3067612e-03 -1.4139424e-03\n",
      "  4.8348933e-04 -7.4332400e-04  1.0340433e-03 -6.5387040e-04\n",
      " -3.7799173e-04  6.2503881e-04  6.7691575e-04 -2.1271415e-03\n",
      "  9.8329270e-04 -6.9750461e-04  1.5788485e-03 -1.8792505e-03\n",
      " -3.2419271e-03 -2.4909005e-03 -9.3217078e-04 -2.0107024e-03\n",
      "  1.6659360e-03  2.4547131e-04  3.4921027e-03  2.5711050e-03\n",
      "  1.0874633e-03 -2.6961511e-03 -3.6281958e-04 -1.5031504e-03\n",
      "  9.5925492e-04 -5.8511982e-04  2.2062857e-03  1.9385517e-04\n",
      "  2.7537916e-03  1.3694788e-03 -1.3388012e-03  1.2939180e-03\n",
      " -2.2814558e-03  1.5458089e-03  1.3685679e-03  2.5028586e-03\n",
      "  5.8458038e-05 -1.2642446e-03 -2.0274408e-03  2.3032459e-03\n",
      "  1.0547810e-03 -2.1709385e-03 -1.0554012e-03  9.8363787e-04\n",
      "  2.4780247e-03 -4.9114582e-04  1.8725505e-03 -1.6442470e-03\n",
      " -2.4715008e-03  1.7933943e-03 -7.6845015e-04 -2.1476329e-03\n",
      "  3.1239112e-04  7.6207978e-04 -6.5708841e-04 -1.8732486e-03\n",
      "  1.3789717e-03 -1.9760137e-04 -1.1568454e-05  2.1115316e-03\n",
      " -1.5344976e-03  1.6486844e-03 -2.0387394e-03 -3.5684831e-03\n",
      " -1.4058972e-03  1.7432347e-03 -1.4721421e-03 -2.2909946e-04\n",
      "  1.4851892e-03  1.2635817e-03 -2.0591051e-03 -7.9501962e-04\n",
      " -1.5489344e-03 -2.6426054e-04 -1.1202436e-03  2.8150070e-03\n",
      " -1.1800136e-03 -2.3409126e-03 -2.2870866e-03  5.8623706e-04]\n"
     ]
    }
   ],
   "source": [
    "print(model_ft.wv['brown']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1c7c403-289c-4eed-8266-9881b3c74ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words most similar to 'sentence':\n",
      "[('the', 0.31603533029556274), ('dog', 0.2715560495853424), ('weather', 0.21614959836006165), ('today', 0.1918906569480896), ('recognition', 0.19100384414196014)]\n",
      "\n",
      "Words most similar to OOV word 'anothersentenceexample':\n",
      "[('computer', 0.48188263177871704), ('computers', 0.47151511907577515), ('learning', 0.4620915651321411), ('learn', 0.272807776927948), ('today', 0.21645088493824005)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence1 = 'cat in the wall'\n",
    "sentence2= 'the weather is cloudy today'\n",
    "# Find the most similar words to 'sentence'\n",
    "similar_words = model_ft.wv.most_similar(sentence2, topn=5)\n",
    "print(f\"Words most similar to 'sentence':\\n{similar_words}\\n\")\n",
    "\n",
    "# Find most similar words, even for OOV words\n",
    "similar_oov = model_ft.wv.most_similar('learning computer for one year', topn=5)\n",
    "print(f\"Words most similar to OOV word 'anothersentenceexample':\\n{similar_oov}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "592c5e64-7b5b-4cce-8041-1713452039a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'sentence' and 'word2vec': 0.029605142772197723\n",
      "\n",
      "Similarity between 'sentence' and OOV word 'totallynewword': 0.21614959836006165\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence1 = 'cat in the wall'\n",
    "# Calculate the similarity between two words\n",
    "similarity = model_ft.wv.similarity(sentence1, 'rat')\n",
    "print(f\"Similarity between 'sentence' and 'word2vec': {similarity}\\n\")\n",
    "sentence2= 'the weather is cloudy today'\n",
    "similarity_oov = model_ft.wv.similarity(sentence2, 'weather')\n",
    "print(f\"Similarity between 'sentence' and OOV word 'totallynewword': {similarity_oov}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1dd61eb-b481-4564-aded-5ee548007b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_score = model_ft.wv.similarity('man', 'human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae6959bc-a5d6-4286-a6c5-183f4a81af30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24681632\n"
     ]
    }
   ],
   "source": [
    "print(sim_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f0ebd3-d0dc-491f-a54d-8b07f8baa1b3",
   "metadata": {},
   "source": [
    "### Code from internet using chatgpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "175a67b2-35f2-428e-aa30-2a4e4b62b6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample corpus:\n",
      "[['human', 'interface', 'computer'],\n",
      " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
      " ['eps', 'user', 'interface', 'system'],\n",
      " ['system', 'human', 'system', 'eps'],\n",
      " ['user', 'response', 'time'],\n",
      " ['trees'],\n",
      " ['graph', 'trees'],\n",
      " ['graph', 'minors', 'trees'],\n",
      " ['graph', 'minors', 'survey']]\n",
      "\n",
      "Vector for 'computer':\n",
      " [ 2.96936167e-04  3.31060466e-04 -8.77768325e-04  3.39444174e-04\n",
      " -5.01747418e-04 -2.04214524e-03 -1.24066719e-03 -1.94044539e-03\n",
      "  1.34510931e-03 -2.41268426e-03  9.18505422e-04 -1.03151030e-03\n",
      " -7.63410062e-04  7.31222244e-05  1.38286629e-03  5.19435504e-04\n",
      " -2.98849802e-04 -1.19464763e-03 -1.17238448e-03 -6.08951552e-04\n",
      " -6.78338984e-04  3.92779708e-04  9.88251195e-05  8.12689308e-04\n",
      "  5.81971311e-04  7.01953366e-04 -7.36806658e-04 -1.03962549e-03\n",
      " -6.25258312e-04 -2.40496884e-04 -1.19316357e-03 -2.65940849e-04\n",
      "  7.36046524e-04 -7.21505727e-04 -1.27508014e-03  1.24231781e-04\n",
      "  3.77583550e-04 -1.33155228e-03 -2.73441360e-03 -3.04829708e-04\n",
      "  9.28272377e-04 -7.28168816e-04 -1.12919568e-03 -3.21931177e-04\n",
      " -2.06016310e-04 -1.04854174e-04 -6.22976047e-04 -1.61377620e-03\n",
      "  9.91107081e-04  9.22983818e-05  3.68000241e-04 -5.37839776e-04\n",
      "  1.13322982e-03  8.70750577e-04 -1.63867278e-03 -8.55855411e-04\n",
      " -6.31069415e-04  6.22909865e-04  8.40167049e-04 -1.12830219e-03\n",
      "  1.29163847e-03 -3.40488943e-04 -1.17833621e-03 -1.60850491e-03\n",
      "  1.52693118e-03  3.01169712e-05 -2.41883954e-05 -7.27596227e-04\n",
      "  1.73330551e-03  8.93421762e-04  3.26789886e-04 -4.63379052e-04\n",
      " -2.31358409e-03 -1.72005536e-03  4.35937254e-04 -4.12225461e-04\n",
      " -1.06689101e-03 -1.00902386e-03 -1.64344837e-03 -1.05065810e-04\n",
      "  1.01913651e-03 -6.24372798e-04 -1.08174444e-03  8.85603193e-04\n",
      " -1.45729631e-03  6.48391724e-04  4.41413518e-04 -1.24500669e-03\n",
      "  3.49245267e-04 -9.81050660e-04 -9.73784481e-04 -1.98150854e-04\n",
      " -1.89508792e-04 -9.85311344e-04  5.74433478e-04  1.99000956e-03\n",
      "  7.19957534e-05  9.95708513e-04 -1.70885876e-03  1.34901761e-03]\n",
      "\n",
      "Words similar to 'computer':\n",
      "[('user', 0.15659412741661072),\n",
      " ('response', 0.12383823096752167),\n",
      " ('eps', 0.030704917386174202),\n",
      " ('system', 0.02557387575507164),\n",
      " ('interface', 0.005858737975358963),\n",
      " ('survey', -0.03156976401805878),\n",
      " ('minors', -0.05455649644136429),\n",
      " ('human', -0.0668589174747467),\n",
      " ('time', -0.06855931878089905),\n",
      " ('trees', -0.10636083036661148)]\n",
      "\n",
      "Vector for misspelled 'compuuter':\n",
      " [ 5.37822256e-04  8.13040300e-04  2.86898983e-04  3.45453183e-04\n",
      " -3.63900501e-04 -8.91792006e-04 -1.07653148e-03 -2.65255850e-03\n",
      "  1.23973237e-03 -1.08289874e-04 -2.04619173e-05  2.71872792e-04\n",
      " -2.53348146e-03  7.76573201e-04  1.85995072e-04 -5.25655982e-04\n",
      "  1.37992043e-04 -7.77879613e-04 -2.20079767e-03 -1.84260149e-04\n",
      " -8.84888927e-04  1.64963049e-03 -1.51548896e-03  5.80495223e-04\n",
      "  1.09000551e-03  1.43722841e-03 -1.90578937e-03 -1.08204995e-05\n",
      "  1.39688689e-03  4.18723939e-04 -5.09811915e-04  3.11804877e-04\n",
      "  1.97143061e-03 -1.47492683e-03  3.38606245e-04  1.16263342e-03\n",
      "  1.47270760e-03 -2.10537040e-03 -1.75831176e-03 -5.03999298e-04\n",
      "  1.76466804e-03 -5.19507390e-04  6.85872510e-04 -6.02523971e-04\n",
      " -9.15401499e-04  3.57487297e-04 -7.29428371e-04 -7.87281024e-04\n",
      "  2.02886132e-03  7.51795247e-04 -6.72323658e-05 -2.23634779e-04\n",
      "  8.76179023e-04 -1.69347040e-04 -1.35133113e-03 -4.21586767e-04\n",
      " -8.60555796e-04  8.67682174e-05  4.87919751e-04 -3.50769697e-04\n",
      " -2.90343378e-05  3.78279947e-06 -1.79809600e-03 -4.29539912e-04\n",
      "  7.47438404e-04 -8.46476876e-04  6.62479666e-04 -3.10997275e-04\n",
      "  1.32820650e-03  3.53045383e-04  9.22459993e-04 -1.75035582e-03\n",
      " -2.05549225e-03 -2.05196161e-03 -4.94325242e-04 -1.68996560e-03\n",
      " -1.81310592e-04  1.12795166e-03 -3.06170114e-04  4.14203969e-04\n",
      " -9.85328807e-04 -1.28988875e-03 -1.31777677e-04  1.69355806e-03\n",
      " -1.16845162e-03  1.16397394e-03 -4.07498825e-04 -1.70077092e-03\n",
      "  1.18601054e-03 -5.72660065e-04 -5.10007318e-04 -1.17064337e-03\n",
      " -1.07545615e-03 -2.10420322e-03 -2.11223465e-04  2.40667001e-03\n",
      " -6.50291971e-04 -1.95746412e-04 -6.48648303e-04  1.95697858e-03]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import FastText\n",
    "from gensim.test.utils import common_texts  # Example corpus\n",
    "from pprint import pprint\n",
    "\n",
    "# Example corpus (you can use your own preprocessed text data)\n",
    "print(\"Sample corpus:\")\n",
    "pprint(common_texts)\n",
    "\n",
    "# Train FastText model\n",
    "model = FastText(sentences=common_texts, vector_size=100, window=5, min_count=1, workers=4, sg=1)\n",
    "\n",
    "# Save and load the model\n",
    "model.save(\"fasttext.model\")\n",
    "model = FastText.load(\"fasttext.model\")\n",
    "\n",
    "# Example: Get vector for a word\n",
    "word_vector = model.wv['computer']\n",
    "print(\"\\nVector for 'computer':\\n\", word_vector)\n",
    "\n",
    "# Find similar words\n",
    "similar_words = model.wv.most_similar('computer')\n",
    "print(\"\\nWords similar to 'computer':\")\n",
    "pprint(similar_words)\n",
    "\n",
    "# Handle out-of-vocabulary (OOV) word\n",
    "oov_vector = model.wv['compuuter']  # misspelled\n",
    "print(\"\\nVector for misspelled 'compuuter':\\n\", oov_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a192dc-8a70-4073-bb02-1c5199bb30d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIvenv",
   "language": "python",
   "name": "aivenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
